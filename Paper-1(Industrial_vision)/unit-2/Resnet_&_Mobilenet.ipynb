{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "mount_file_id": "1KODBeOY3kMJQNs4OP8aCv_rxZtMvuLdn",
      "authorship_tag": "ABX9TyMelsSFp+S1DCuHKU5153zh",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Sivachandran5710/HCL-training/blob/main/Paper-1(Industrial_vision)/unit-2/Resnet_%26_Mobilenet.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QpJHA0DqMqQQ",
        "outputId": "3abb0866-426c-4e12-f65e-a03e6fa66511"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "TensorFlow version: 2.19.0\n",
            "Training ResNet50...\n",
            "Epoch 1/3\n",
            "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m185s\u001b[0m 112ms/step - accuracy: 0.1076 - loss: 2.3702 - val_accuracy: 0.1276 - val_loss: 2.2927\n",
            "Epoch 2/3\n",
            "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m154s\u001b[0m 98ms/step - accuracy: 0.1330 - loss: 2.2907 - val_accuracy: 0.1646 - val_loss: 2.2787\n",
            "Epoch 3/3\n",
            "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m155s\u001b[0m 99ms/step - accuracy: 0.1513 - loss: 2.2746 - val_accuracy: 0.2115 - val_loss: 2.2561\n",
            "Fine-tuning ResNet50...\n",
            "Epoch 1/2\n",
            "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m239s\u001b[0m 141ms/step - accuracy: 0.3190 - loss: 1.8917 - val_accuracy: 0.4134 - val_loss: 1.6160\n",
            "Epoch 2/2\n",
            "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m211s\u001b[0m 135ms/step - accuracy: 0.4816 - loss: 1.4549 - val_accuracy: 0.4704 - val_loss: 1.4682\n",
            "Model saved in .keras format.\n"
          ]
        }
      ],
      "source": [
        "# -------------------------------------\n",
        "# 1. Setup (Colab has TF pre-installed)\n",
        "# -------------------------------------\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers, models\n",
        "\n",
        "print(\"TensorFlow version:\", tf.__version__)\n",
        "\n",
        "# -------------------------------------\n",
        "# 2. Load a sample dataset (replace with your own)\n",
        "# Colab provides tf.keras.datasets, here we use CIFAR-10 for demo\n",
        "# -------------------------------------\n",
        "(x_train, y_train), (x_val, y_val) = tf.keras.datasets.cifar10.load_data()\n",
        "\n",
        "# Normalize images\n",
        "x_train = x_train.astype(\"float32\") / 255.0\n",
        "x_val = x_val.astype(\"float32\") / 255.0\n",
        "\n",
        "# Resize images to 224x224 (needed for ResNet/MobileNet)\n",
        "resize_layer = tf.keras.Sequential([\n",
        "    layers.Resizing(224, 224)\n",
        "])\n",
        "\n",
        "train_ds = tf.data.Dataset.from_tensor_slices((x_train, y_train)).batch(32).map(lambda x, y: (resize_layer(x), y))\n",
        "val_ds = tf.data.Dataset.from_tensor_slices((x_val, y_val)).batch(32).map(lambda x, y: (resize_layer(x), y))\n",
        "\n",
        "# -------------------------------------\n",
        "# 3. Transfer Learning with ResNet50\n",
        "# -------------------------------------\n",
        "base_resnet = tf.keras.applications.ResNet50(\n",
        "    weights=\"imagenet\",\n",
        "    include_top=False,\n",
        "    input_shape=(224, 224, 3)\n",
        ")\n",
        "\n",
        "base_resnet.trainable = False  # freeze backbone\n",
        "\n",
        "resnet_model = models.Sequential([\n",
        "    base_resnet,\n",
        "    layers.GlobalAveragePooling2D(),\n",
        "    layers.Dense(256, activation=\"relu\"),\n",
        "    layers.Dropout(0.5),\n",
        "    layers.Dense(10, activation=\"softmax\")  # CIFAR-10 has 10 classes\n",
        "])\n",
        "\n",
        "resnet_model.compile(\n",
        "    optimizer=tf.keras.optimizers.Adam(1e-4),\n",
        "    loss=\"sparse_categorical_crossentropy\",\n",
        "    metrics=[\"accuracy\"]\n",
        ")\n",
        "\n",
        "print(\"Training ResNet50...\")\n",
        "resnet_model.fit(train_ds, validation_data=val_ds, epochs=3)\n",
        "\n",
        "\n",
        "# -------------------------------------\n",
        "# 4. Fine-tuning (optional: unfreeze last few layers)\n",
        "# -------------------------------------\n",
        "base_resnet.trainable = True\n",
        "for layer in base_resnet.layers[:-30]:\n",
        "    layer.trainable = False\n",
        "\n",
        "resnet_model.compile(\n",
        "    optimizer=tf.keras.optimizers.Adam(1e-5),  # lower LR\n",
        "    loss=\"sparse_categorical_crossentropy\",\n",
        "    metrics=[\"accuracy\"]\n",
        ")\n",
        "\n",
        "print(\"Fine-tuning ResNet50...\")\n",
        "resnet_model.fit(train_ds, validation_data=val_ds, epochs=2)\n",
        "# -------------------------------------\n",
        "# 5. Save the trained model\n",
        "# -------------------------------------\n",
        "\n",
        "# Recommended: Save in the modern Keras v3 format\n",
        "resnet_model.save('resnet_cifar10.keras')\n",
        "print(\"Model saved in .keras format.\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SyN6ZsfKQ0ll",
        "outputId": "a3c8606b-43bd-4489-b1df-814f86a457b3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from tensorflow.keras.preprocessing import image\n",
        "\n",
        "img_path = \"/content/drive/My Drive/images/cat.jpg\"\n",
        "img = image.load_img(img_path, target_size=(224, 224))\n",
        "img_array = image.img_to_array(img) / 255.0\n",
        "img_array = np.expand_dims(img_array, axis=0)  # batch dimension\n",
        "\n",
        "pred_probs = resnet_model.predict(img_array)\n",
        "pred_class = np.argmax(pred_probs, axis=1)[0]\n",
        "\n",
        "print(\"Predicted class:\", pred_class)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TiVTuh2POcAV",
        "outputId": "90354ba7-8946-47f6-9557-bb8ad1230188"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4s/step\n",
            "Predicted class: 3\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from tensorflow.keras.preprocessing import image\n",
        "\n",
        "img_path = \"/content/drive/My Drive/images/aero.jpg\"\n",
        "img = image.load_img(img_path, target_size=(224, 224))\n",
        "img_array = image.img_to_array(img) / 255.0\n",
        "img_array = np.expand_dims(img_array, axis=0)  # batch dimension\n",
        "\n",
        "pred_probs = resnet_model.predict(img_array)\n",
        "pred_class = np.argmax(pred_probs, axis=1)[0]\n",
        "\n",
        "print(\"Predicted class:\", pred_class)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9YsRIKanTC3r",
        "outputId": "5461c5f4-ea18-487d-cfdb-b9580de4c49c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 52ms/step\n",
            "Predicted class: 0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from tensorflow.keras.preprocessing import image\n",
        "\n",
        "img_path = \"/content/drive/My Drive/images/auto.jpg\"\n",
        "img = image.load_img(img_path, target_size=(224, 224))\n",
        "img_array = image.img_to_array(img) / 255.0\n",
        "img_array = np.expand_dims(img_array, axis=0)  # batch dimension\n",
        "\n",
        "pred_probs = resnet_model.predict(img_array)\n",
        "pred_class = np.argmax(pred_probs, axis=1)[0]\n",
        "\n",
        "print(\"Predicted class:\", pred_class)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ac1512c9-ce94-4250-ebe6-0345f93f442e",
        "id": "J8MXs25iTDgJ"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 78ms/step\n",
            "Predicted class: 1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from tensorflow.keras.preprocessing import image\n",
        "\n",
        "img_path = \"/content/drive/My Drive/images/deer.jpg\"\n",
        "img = image.load_img(img_path, target_size=(224, 224))\n",
        "img_array = image.img_to_array(img) / 255.0\n",
        "img_array = np.expand_dims(img_array, axis=0)  # batch dimension\n",
        "\n",
        "pred_probs = resnet_model.predict(img_array)\n",
        "pred_class = np.argmax(pred_probs, axis=1)[0]\n",
        "\n",
        "print(\"Predicted class:\", pred_class)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3topmHOjTSIJ",
        "outputId": "f531b5b0-a8e4-4ec2-c543-71411ff3d958"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step\n",
            "Predicted class: 6\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# -------------------------------------\n",
        "# 1. Setup\n",
        "# -------------------------------------\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers, models\n",
        "\n",
        "print(\"TensorFlow version:\", tf.__version__)\n",
        "\n",
        "# -------------------------------------\n",
        "# 2. Load dataset (CIFAR-10)\n",
        "# -------------------------------------\n",
        "(x_train, y_train), (x_val, y_val) = tf.keras.datasets.cifar10.load_data()\n",
        "\n",
        "# Normalize images\n",
        "x_train = x_train.astype(\"float32\") / 255.0\n",
        "x_val = x_val.astype(\"float32\") / 255.0\n",
        "\n",
        "# Resize to 224x224 for MobileNetV2\n",
        "resize_layer = tf.keras.Sequential([\n",
        "    layers.Resizing(224, 224)\n",
        "])\n",
        "\n",
        "train_ds = tf.data.Dataset.from_tensor_slices((x_train, y_train)).batch(32).map(lambda x, y: (resize_layer(x), y))\n",
        "val_ds = tf.data.Dataset.from_tensor_slices((x_val, y_val)).batch(32).map(lambda x, y: (resize_layer(x), y))\n",
        "\n",
        "# -------------------------------------\n",
        "# 3. Transfer Learning with MobileNetV2\n",
        "# -------------------------------------\n",
        "# Load pre-trained MobileNetV2\n",
        "base_model = tf.keras.applications.MobileNetV2(\n",
        "    weights=\"imagenet\",\n",
        "    include_top=False,\n",
        "    input_shape=(224, 224, 3)\n",
        ")\n",
        "\n",
        "# Freeze the base model\n",
        "base_model.trainable = False\n",
        "\n",
        "# Build the full model\n",
        "model = models.Sequential([\n",
        "    base_model,\n",
        "    layers.GlobalAveragePooling2D(),\n",
        "    layers.Dense(256, activation='relu'),\n",
        "    layers.Dropout(0.5),\n",
        "    layers.Dense(10, activation='softmax')  # CIFAR-10 has 10 classes\n",
        "])\n",
        "\n",
        "# Compile\n",
        "model.compile(\n",
        "    optimizer=tf.keras.optimizers.Adam(1e-4),\n",
        "    loss='sparse_categorical_crossentropy',\n",
        "    metrics=['accuracy']\n",
        ")\n",
        "\n",
        "print(\"Training MobileNetV2...\")\n",
        "history = model.fit(train_ds, validation_data=val_ds, epochs=3)\n",
        "\n",
        "# -------------------------------------\n",
        "# 4. Fine-tuning: unfreeze top layers of base model\n",
        "# -------------------------------------\n",
        "# Now make the base model trainable\n",
        "base_model.trainable = True\n",
        "\n",
        "# Freeze all layers except the last 30\n",
        "for layer in base_model.layers[:-30]:\n",
        "    layer.trainable = False\n",
        "\n",
        "# Recompile with lower learning rate\n",
        "model.compile(\n",
        "    optimizer=tf.keras.optimizers.Adam(1e-5),\n",
        "    loss='sparse_categorical_crossentropy',\n",
        "    metrics=['accuracy']\n",
        ")\n",
        "\n",
        "print(\"Fine-tuning MobileNetV2...\")\n",
        "history_fine = model.fit(train_ds, validation_data=val_ds, epochs=2)\n",
        "\n",
        "# -------------------------------------\n",
        "# 5. Save the trained model\n",
        "# -------------------------------------\n",
        "model.save('mobilenet_cifar10.keras')\n",
        "print(\"Model saved in .keras format.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zs4EwgJRR-KK",
        "outputId": "5b3fc55c-a734-4767-af45-ff7719d1a7bb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "TensorFlow version: 2.19.0\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/mobilenet_v2/mobilenet_v2_weights_tf_dim_ordering_tf_kernels_1.0_224_no_top.h5\n",
            "\u001b[1m9406464/9406464\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0us/step\n",
            "Training MobileNetV2...\n",
            "Epoch 1/3\n",
            "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m90s\u001b[0m 47ms/step - accuracy: 0.5508 - loss: 1.3282 - val_accuracy: 0.7747 - val_loss: 0.6549\n",
            "Epoch 2/3\n",
            "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m54s\u001b[0m 35ms/step - accuracy: 0.7503 - loss: 0.7210 - val_accuracy: 0.7942 - val_loss: 0.5888\n",
            "Epoch 3/3\n",
            "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m56s\u001b[0m 36ms/step - accuracy: 0.7803 - loss: 0.6395 - val_accuracy: 0.8023 - val_loss: 0.5628\n",
            "Fine-tuning MobileNetV2...\n",
            "Epoch 1/2\n",
            "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m99s\u001b[0m 52ms/step - accuracy: 0.7107 - loss: 0.8415 - val_accuracy: 0.8232 - val_loss: 0.5113\n",
            "Epoch 2/2\n",
            "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m67s\u001b[0m 43ms/step - accuracy: 0.8197 - loss: 0.5343 - val_accuracy: 0.8408 - val_loss: 0.4555\n",
            "Model saved in .keras format.\n"
          ]
        }
      ]
    }
  ]
}